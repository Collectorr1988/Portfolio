{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #CCCCFF; border-radius: 1px;\">\n",
    "<div style=\"margin: 5px\">\n",
    "<b class=\"alert-heading\">Комментарий ревьюера</b>\n",
    "<p>Дмитрий, привет!</p>\n",
    "<p>Меня зовут Алексей Секоцкий. Поздравляю с подготовкой очередного проекта. Предлагаю обращаться друг к другу на «ты» если нет возражений. Ниже стандартный блок с условными обозначениями:</p>\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "всё отлично\n",
    "</div>\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "рекомендации на будущее (не требующие доработки проекта)\n",
    "</div>\n",
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "критичные моменты требующие внимания (доработки)\n",
    "</div>\n",
    "<div class=\"alert alert-info\">\n",
    "итоговый комментарий\n",
    "</div>\n",
    "\n",
    "<hr>\n",
    "<p>Пожалуйста, не изменяй и не удаляй мои комментарии – они потребуются для повторной проверки (при необходимости). Задавай вопросы и описывай сделанные изменения, помечая их любым удобным наглядным способом.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Вводный комментарий от ревьюера</b>\n",
    "\n",
    "Попробовал перезапустить проект в хабе, т.к. изначально было выдано много ошибок. На Дереве с перебором глубины от 100 до 150 это длилось больше часа (сколько точно не знаю – оставил комп и ушел) :))) Можно перебирать и десятками, поэтому лучше изменить параметр хотя бы на (100, 151, 10). Дальше не дошел. Ниже будут комментарии по ходу проекта.\n",
    "<hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Комментарий от студента</b>\n",
    "Привет, Алексей! Спасибо за оперативную проверку. Попробовал поправить с учетом комментариев. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='table of contents'>Содержание</a>  \n",
    "<a href='#part1'>1. ПОСТАНОВКА ЗАДАЧИ</a>     \n",
    "<a href='#part2'>2. ЗАГРУЗКА И ОПИСАНИЕ ДАННЫХ</a>    \n",
    "<a href='#part3'>3. ПРЕДОБРАБОТКА ДАННЫХ</a>      \n",
    "<a href='#part4'>4. ОБУЧЕНИЕ МОДЕЛЕЙ</a>      \n",
    "<a href='#part5'>5 ВЫВОДЫ И ВОПРОСЫ </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='part1'>1. ПОСТАНОВКА ЗАДАЧИ</a>\n",
    "<a href='#table of contents'>к оглавлению</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Цель:*** Обучить модель классификации, которая будет выявлять токсичные комментарии.   \n",
    "***Целевая метрика:*** - F1, значение должно быть не меньше 0,75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='part2'> 2. ЗАГРУЗКА И ОПИСАНИЕ ДАННЫХ</a>\n",
    "<a href='#table of contents'>к оглавлению</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "pd.options.mode.chained_assignment = None\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMModel,LGBMClassifier\n",
    "try:\n",
    "    df=pd.read_csv('toxic_comments.csv') \n",
    "except: \n",
    "    df=pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Лишние библиотеки лучше убрать. Толку от них нет, а оперативку могут отъедать. CatBoostRegressor вообще случайно попал :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Комментарий от студента</b>\n",
    "Сделано\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hjhkljhgfd\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\hjhkljhgfd\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: regex in c:\\users\\hjhkljhgfd\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hjhkljhgfd\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: click in c:\\users\\hjhkljhgfd\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hjhkljhgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим баланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898321\n",
      "1    0.101679\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Класс')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency=df['toxic'].value_counts(normalize=2/len(df))\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')\n",
    "plt.ylabel(\"Доля класса\")\n",
    "plt.xlabel(\"Класс\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Вывод 1***  \n",
    "* Пропуски в данных отсутствуют.\n",
    "* Существует дисбаланс классов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Отлично. Данные загружены и изучены.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='part3'>3. ПРЕДОБРАБОТКА ДАННЫХ </a>\n",
    "<a href='#table of contents'>к оглавлению</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим библиотеку WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hjhkljhgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hjhkljhgfd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим корпус с твитами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию для подготовки текста к векторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparate_to_education(text):\n",
    "    lemmer=WordNetLemmatizer()\n",
    "    words=nltk.word_tokenize(text)   #разобъем твиты на слова \n",
    "    words_lemmatize=' '.join([lemmer.lemmatize(word) for word in words])  #лемматизируем слова и соединим в предложения\n",
    "    text_eng=re.sub(r'[^a-zA-Z ]', ' ', words_lemmatize)   #удалим лишние знаки\n",
    "    text_split=\" \".join(text_eng.split())   #удалим лишние пробелы и соединим слова через пробелы\n",
    "    return text_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим твиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lemmatize=corpus.apply(preparate_to_education)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим лемматизированный столбец в датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_prepare']=corpus_lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_prepare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i ca n t make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm there no actual article for prosti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it wa actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really do n t think you understand i cam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                             text_prepare  \n",
       "0       explanation why the edits made under my userna...  \n",
       "1       d aww he match this background colour i m seem...  \n",
       "2       hey man i m really not trying to edit war it s...  \n",
       "3       more i ca n t make any real suggestion on impr...  \n",
       "4       you sir are my hero any chance you remember wh...  \n",
       "...                                                   ...  \n",
       "159566  and for the second time of asking when your vi...  \n",
       "159567  you should be ashamed of yourself that is a ho...  \n",
       "159568  spitzer umm there no actual article for prosti...  \n",
       "159569  and it look like it wa actually you who put on...  \n",
       "159570  and i really do n t think you understand i cam...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Лемматизация – это хорошо. Как бонус – не обязательно делать очистку и переводить в нижний регистр.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='part4'>4. ОБУЧЕНИЕ МОДЕЛЕЙ </a>\n",
    "<a href='#table of contents'>к оглавлению</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на тренировочную, валидационную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df['text_prepare'].values\n",
    "target=df['toxic'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на тренировочную, валидационную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получим тренировочную и тестовую выборки\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "#получим валидационную выборку\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "features_train, target_train, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем TFIDF для всех выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_eng=stopwords.words('english')\n",
    "count_tf_idf=TfidfVectorizer(stop_words=stop_words_eng) #если убрать стоп-слова, то никак не получается метрика выше 0,748. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Передается ли в count_tf_idf=TfidfVectorizer() параметр stopwords.words('english')?\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Комментарий от студента</b>Сейчас с LGBM норм\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = count_tf_idf.fit_transform(features_train)\n",
    "tf_idf_valid = count_tf_idf.transform(features_valid)\n",
    "tf_idf_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83774, 110998)\n",
      "(39893, 110998)\n",
      "(35904, 110998)\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_train.shape)\n",
    "print(tf_idf_test.shape)\n",
    "print(tf_idf_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "Деление неравномерное. Валидационная выборка меньше тестовой. Так задумано?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Комментарий от студента</b>\n",
    "Поправил\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера 2</b>\n",
    "\n",
    "Всё равно меньше :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию для обучения моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_model (data_features_train, data_target_train,  #функция принимает данные и модель\n",
    "                    data_features_valid, data_target_valid, \n",
    "                    data_features_test, data_target_test,\n",
    "                    model):\n",
    "    \n",
    "    model.fit(data_features_train, data_target_train)     #обучим модель \n",
    "    predictions_valid=model.predict(data_features_valid) #сделаем предсказания на валидационной выборке\n",
    "    predicted_test=model.predict(data_features_test)     #сделаем предсказания на тестовой выборке\n",
    "    \n",
    "    result__valid=f1_score(data_target_valid, predictions_valid) #посчитаем метрику на валидационной выборке\n",
    "    result__test=f1_score(data_target_test, predicted_test) #посчитаем метрику на тестовой выборке\n",
    "\n",
    "    print('F1_score на валидационной выборке: ', result__valid)\n",
    "    print('F1_score на тестовой выборке: ', result__test)\n",
    "\n",
    "\n",
    "    return result__valid, result__test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Не очень понимаю смысл обучать сразу на всех выборках. Поидее на валидационной мы подбираем гиперпараметры, а на тестовой уже тестируем лучшие модели.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Комментарий студента</b>\n",
    "Я обучаю модель только на тренировочной выборке, а на тестовой и валидационной делаю \n",
    "предсказание,чтобы контролировать переобучение\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера 2</b>\n",
    "\n",
    "Да, я не очень точно выразился. Непосредствнно обучение, конечно, на тренировочной, однако, оценка модели идет как на валидационной , так и на тестовой. Тестовую лучше оставить для контроля и не подгонять под нее гиперпараметры. В проде мы же не знаем какие данные нам придут, поэтому не можем модель под них подогнать. Модель должна хорошо работать на условно неизвестных нам данных.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ОБУЧИМ МОДЕЛЬ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***L1 регуляризация***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score на валидационной выборке:  0.7210649574756565\n",
      "F1_score на тестовой выборке:  0.7174344280361473\n",
      "F1_score на валидационной выборке:  0.7265980368685658\n",
      "F1_score на тестовой выборке:  0.7239982949701619\n",
      "F1_score на валидационной выборке:  0.7299287410926365\n",
      "F1_score на тестовой выборке:  0.7304769945124524\n",
      "F1_score на валидационной выборке:  0.7310655446248666\n",
      "F1_score на тестовой выборке:  0.7304019309476335\n",
      "F1_score на валидационной выборке:  0.7357685009487666\n",
      "F1_score на тестовой выборке:  0.7340737636211232\n",
      "F1_score на валидационной выборке:  0.7365795724465558\n",
      "F1_score на тестовой выборке:  0.7353713625380818\n",
      "F1_score на валидационной выборке:  0.7401049117787315\n",
      "F1_score на тестовой выборке:  0.7376169944263329\n",
      "F1_score на валидационной выборке:  0.7426241304869272\n",
      "F1_score на тестовой выборке:  0.740403933594163\n",
      "F1_score на валидационной выборке:  0.7435712569093968\n",
      "F1_score на тестовой выборке:  0.7419183889772124\n",
      "F1_score на валидационной выборке:  0.7437876960193003\n",
      "F1_score на тестовой выборке:  0.7442752156779211\n",
      "F1_score на валидационной выборке:  0.7454017424975798\n",
      "F1_score на тестовой выборке:  0.747139955094622\n",
      "F1_score на валидационной выборке:  0.7474796550467631\n",
      "F1_score на тестовой выборке:  0.7491135704308586\n",
      "F1_score на валидационной выборке:  0.7490243902439024\n",
      "F1_score на тестовой выборке:  0.7505390254420009\n",
      "F1_score на валидационной выборке:  0.750275296708675\n",
      "F1_score на тестовой выборке:  0.752408790732922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjhkljhgfd\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score на валидационной выборке:  0.7515970515970516\n",
      "F1_score на тестовой выборке:  0.7529923830250272\n",
      "F1_score на валидационной выборке:  0.7524044389642416\n",
      "F1_score на тестовой выборке:  0.7541448516579407\n",
      "F1_score на валидационной выборке:  0.7532210109018832\n",
      "F1_score на тестовой выборке:  0.7553319479383135\n",
      "F1_score на валидационной выборке:  0.752856433184302\n",
      "F1_score на тестовой выборке:  0.757266644729626\n",
      "F1_score на валидационной выборке:  0.753547423450336\n",
      "F1_score на тестовой выборке:  0.7582792386401144\n",
      "F1_score на валидационной выборке:  0.7547122706278867\n",
      "F1_score на тестовой выборке:  0.75774616826552\n",
      "F1_score на валидационной выборке:  0.7561342013019529\n",
      "F1_score на тестовой выборке:  0.7579949098152042\n",
      "F1_score на валидационной выборке:  0.7569671102184283\n",
      "F1_score на тестовой выборке:  0.7589038056141129\n",
      "F1_score на валидационной выборке:  0.7575719492270956\n",
      "F1_score на тестовой выборке:  0.758367619259424\n",
      "F1_score на валидационной выборке:  0.7570834907442388\n",
      "F1_score на тестовой выборке:  0.7576601671309193\n",
      "F1_score на валидационной выборке:  0.7573158425832492\n",
      "F1_score на тестовой выборке:  0.7574810183117463\n",
      "F1_score на валидационной выборке:  0.7580971659919028\n",
      "F1_score на тестовой выборке:  0.7583809844152932\n",
      "F1_score на валидационной выборке:  0.7581053698074975\n",
      "F1_score на тестовой выборке:  0.7585121923811663\n"
     ]
    }
   ],
   "source": [
    "for C in np.arange (0.1, 2.8, 0.1):\n",
    "    model_LogisticRegression_L1=LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear', C=C)\n",
    "    learning_model(tf_idf_train, target_train, tf_idf_valid, target_valid, tf_idf_test, target_test, \n",
    "                   model_LogisticRegression_L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***L2 регуляризация***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score на валидационной выборке:  0.7428362394829898\n",
      "F1_score на тестовой выборке:  0.745846817691478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7428362394829898, 0.745846817691478)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LogisticRegression_L1=LogisticRegression(class_weight='balanced', penalty='l2', solver='liblinear')\n",
    "learning_model(tf_idf_train, target_train, tf_idf_valid, target_valid, tf_idf_test, target_test, model_LogisticRegression_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score на валидационной выборке:  0.7428362394829898\n",
      "F1_score на тестовой выборке:  0.746007768666379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7428362394829898, 0.746007768666379)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LogisticRegression_L1=LogisticRegression(class_weight='balanced', penalty='l2', solver='newton-cg')\n",
    "learning_model(tf_idf_train, target_train, tf_idf_valid, target_valid, tf_idf_test, target_test, model_LogisticRegression_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score на валидационной выборке:  0.7428362394829898\n",
      "F1_score на тестовой выборке:  0.746007768666379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7428362394829898, 0.746007768666379)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LogisticRegression_L1=LogisticRegression(class_weight='balanced', penalty='l2', solver='lbfgs', max_iter=800)\n",
    "learning_model(tf_idf_train, target_train, tf_idf_valid, target_valid, tf_idf_test, target_test, model_LogisticRegression_L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Вывод 1:*** Добить логистическую регрсессию до 0.75 не получается. Хотя мы близки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score на валидационной выборке:  0.6956284153005464\n",
      "F1_score на тестовой выборке:  0.7041535098372602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjhkljhgfd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6956284153005464, 0.7041535098372602)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SGDClassifier=SGDClassifier(class_weight='balanced', loss=\"squared_hinge\", penalty=\"l2\", \n",
    "                                  max_iter=4000, random_state=12345)\n",
    "learning_model(tf_idf_train, target_train, tf_idf_valid, target_valid, tf_idf_test, target_test, model_SGDClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Вопрос:***   \n",
    "    Странно, что градиентный спуск дает результат хуже.В чем может быть проблема? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Гиперпараметры неверно подбираются и модель либо неверно обучается, либо переобучается – ничего нового :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ОБУЧИМ ДЕРЕВЯННЫЕ МОДЕЛИ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОБУЧИМ МОДЕЛЬ ДЕРЕВА РЕШЕНИЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score на валидационной выборке:  0.6400892110398663\n",
      "F1_score на тестовой выборке:  0.6434456928838951\n",
      "F1_score на валидационной выборке:  0.6136160429173585\n",
      "F1_score на тестовой выборке:  0.6082322258759496\n",
      "F1_score на валидационной выборке:  0.6251450676982592\n",
      "F1_score на тестовой выборке:  0.612947658402204\n",
      "F1_score на валидационной выборке:  0.6243426959086829\n",
      "F1_score на тестовой выборке:  0.623163648787154\n",
      "F1_score на валидационной выборке:  0.6304069618633222\n",
      "F1_score на тестовой выборке:  0.6294427883512955\n"
     ]
    }
   ],
   "source": [
    "for depth in range(50, 100, 10):\n",
    "    model_DecisionTreeClassifier = DecisionTreeClassifier(random_state=12345, max_depth=depth, class_weight='balanced') \n",
    "    learning_model(tf_idf_train, target_train, tf_idf_valid, target_valid, tf_idf_test, target_test, model_DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОБУЧИМ МОДЕЛЬ СЛУЧАЙНОГО ЛЕСА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем разные виды балансировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score на валидационной выборке:  0.5684016582220176\n",
      "F1_score на тестовой выборке:  0.5583290881304126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5684016582220176, 0.5583290881304126)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RandomForestClassifier=RandomForestClassifier(class_weight='balanced', random_state=123, max_depth=100)\n",
    "learning_model(tf_idf_train, target_train, tf_idf_valid, target_valid, tf_idf_test, target_test, model_RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score на валидационной выборке:  0.6251149108291966\n",
      "F1_score на тестовой выборке:  0.640698238241474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6251149108291966, 0.640698238241474)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RandomForestClassifier=RandomForestClassifier(class_weight='balanced_subsample', random_state=123)\n",
    "learning_model(tf_idf_train, target_train, tf_idf_valid, target_valid, tf_idf_test, target_test, model_RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ОБУЧИМ МОДЕЛЬ ГРАДИЕНТНОГО БУСТИНГА***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Так и есть – ядро падает. Вероятно есть конфликт каких-то библиотек с CatBoost. На данном проекте с ним большие проблемы. Пока непонятно почему. Советую использовать LGBMClassifier. На нем удавалось выжать метрику F1 более 0.75 и даже более 0.80.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Комментарий студента</b>\n",
    "Обычная логистическая регрессия дает результат лучше. Обучение заняло больше часа, а результат всего - 0.709 при параметрах \n",
    "    - 'max_depth': 20, 'n_estimators': 18. Я отключил эти ячейки, чтобы ты не ждал.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера 2</b>\n",
    "\n",
    "У меня на `(random_state=42, num_iterations=200)` и твоих выборках получилась F1=0.83 на трейне и 0.76 на тесте. Обучение заняло несколько минут.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#создадим словарь с перебираемыми параметрами\n",
    "parametrs = { 'n_estimators': range (2, 20, 2),\n",
    "              'max_depth': range (10, 100, 10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model=LGBMClassifier(random_state=42, class_weight='balanced', \n",
    "                     learning_rate=0.5, verbose=10)\n",
    "grid=GridSearchCV(model, parametrs, scoring='f1', cv=3)\n",
    "model_fit=grid.fit(tf_idf_train, target_train)\n",
    "best_score=grid.best_score_\n",
    "print(\"Лучшее f1_score на тренировочных данных:\", abs(best_score))\n",
    "print(\"Лучшие параметры:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='part5'>5. ВЫВОДЫ И ВОПРОСЫ </a>\n",
    "<a href='#table of contents'>к оглавлению</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Вопросы***  \n",
    "1) Ядро умирает на катбусте, все варианты из слака переброваны и ничего не помогло, если подскажешь, что нужно сделать буду благодарен.   \n",
    "2) Почему обучение логистической регрессии градиентным спуском дает результат хуже , чем без него?   \n",
    "3) По факут, сейчас я обучаю модель только на столбце TF-IDF, могу ли я сделать столбец с энграммами (можно сделать несколько таких столбцов) и увеличить таким образом количество признаков для обучения?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Выводы***\n",
    "\n",
    "* Получить метрику выше 0,75 у меня получилось только на логистической регрессии, а все остальные модели дают результат хуже. \n",
    "* Снижение количества данных (если убрать стоп слова) приводит к ухудшение метрики\n",
    "* На моем ноуте я не смог даже загрузить библиотеку с Бертом, про обучение соотвественно речь вообще не идет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Итоговый комментарий ревьюера</b>\n",
    "\n",
    "Начало положено. Просьба не направлять ноутбук с невыполненными кусками кода и с ошибками. Проект должен быть цельным и последовательным. Перед отправкой желательно перезапускать весь ноутбук и направлять если есть увернность, что код выполняется :)\n",
    "<hr>\n",
    "По вопросам:<br>\n",
    "1. В этом проекте про CatBoost забываем :)<br>\n",
    "2. Повторюсь, здесь лучше поробовать LGBM. На бустингах важно подобрать правильные параметры.<br>\n",
    "3. Можно попробовать улучшить метрику используя n-грам в связке с TF-IDF (<a href=\"https://medium.com/machine-learning-intuition/document-classification-part-2-text-processing-eaa26d16c719\">здесь</a> можно почитать подробнее), но я бы рекомендовал для начала завершить то, что уже начали и не распыляться.\n",
    "<hr>\n",
    "Проект можно было бы принять, но тогда он оказался бы немного сыроват. Попробуй учесть мои комментарии. Если возникнут вопросы – смело задавай, постараюсь на них ответить. Буду ждать новую версию.\n",
    "<hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Итоговый комментарий ревьюера</b>\n",
    "\n",
    "Поздравляю с успешной сдачей проекта. Спасибо за старательную работу при подготовке проекта. Желаю успехов в дальнейшем обучении!\n",
    "<hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
